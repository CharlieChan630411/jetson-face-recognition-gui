import argparse
import os
import time
from pathlib import Path

import cv2

# === åƒæ•¸è¨­å®š ===
parser = argparse.ArgumentParser()
parser.add_argument('--name', required=True, help='æª”åå‰ç¶´ (äººå)')
parser.add_argument('--max',  type=int, default=15, help='è‡ªå‹•å­˜åœ–ä¸Šé™')
args = parser.parse_args()

name      = args.name
max_auto  = args.max
save_root = Path('./face-capture/dataset/')
person_dir = save_root / name  # âž¤ æ”¹ç‚ºæ¯äººä¸€å€‹è³‡æ–™å¤¾
person_dir.mkdir(parents=True, exist_ok=True)

# === æ¨¡åž‹è¨­å®š ===
model_path = '/home/user/models/face-dnn/'
prototxt = model_path + 'deploy.prototxt'
weights  = model_path + 'res10_300x300_ssd_iter_140000.caffemodel'

net = cv2.dnn.readNetFromCaffe(prototxt, weights)
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_DEFAULT)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)

# === æ‹ç…§æ¢ä»¶ ===
face_size = (300, 300)
min_face_w = 100
stable_frames = 5
cap = cv2.VideoCapture(0)

counter = 1
stable_count = 0
prev_box = None

print(f"ðŸŸ¢ åµæ¸¬ä¸­ï¼šäººå“¡ {name}ï¼Œæœ€å¤šè‡ªå‹•æ‹ {max_auto} å¼µ")
print("ðŸ“¸ ç©ºç™½éµæ‰‹å‹•æ‹ç…§ï¼Œq é›¢é–‹")

while True:
    ret, frame = cap.read()
    if not ret:
        break

    h, w = frame.shape[:2]
    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300),
                                 (104, 177, 123), swapRB=False)
    net.setInput(blob)
    detections = net.forward()

    face_detected = False
    for i in range(detections.shape[2]):
        conf = detections[0, 0, i, 2]
        if conf > 0.6:
            box = detections[0, 0, i, 3:7] * [w, h, w, h]
            x1, y1, x2, y2 = box.astype(int)
            face_w = x2 - x1
            face_h = y2 - y1

            if face_w < min_face_w or face_h < min_face_w:
                continue

            # âž¤ åˆ¤æ–·æ˜¯å¦ç©©å®š
            if prev_box and abs(x1 - prev_box[0]) < 15 and abs(y1 - prev_box[1]) < 15:
                stable_count += 1
            else:
                stable_count = 0
            prev_box = (x1, y1)

            face_detected = True
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)

            # âž¤ åŠ å…¥æ­£é¢åˆ¤æ–·æ¢ä»¶ï¼ˆå·¦å³å·®è·ä¸å¤§ï¼‰
            face_center_diff = abs((x1 + x2)//2 - w//2)
            if face_center_diff > face_w * 0.3:
                continue  # è‡‰åå¤ªå´ï¼Œä¸å­˜

            # âž¤ è‡ªå‹•å„²å­˜
            if stable_count >= stable_frames and counter <= max_auto:
                face = frame[y1:y2, x1:x2]
                if face.size > 0:
                    face_resize = cv2.resize(face, face_size)

                    # âž¤ è‡ªå‹•é¿é–‹é‡è¤‡æª”å
                    while True:
                        filename = person_dir / f"{name}_{counter}.jpg"
                        if not filename.exists():
                            break
                        counter += 1

                    cv2.imwrite(str(filename), face_resize)
                    print(f"ðŸ“¸ è‡ªå‹•å„²å­˜ {filename.name}")
                    counter += 1
                    stable_count = 0
            break

    cv2.imshow("è‡ªå‹•æŠ“è‡‰æ‹ç…§", frame)

    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        break
    elif key == 32:  # ç©ºç™½éµæ‰‹å‹•æ‹ç…§
        if face_detected:
            face = frame[y1:y2, x1:x2]
            if face.size > 0:
                face_resize = cv2.resize(face, face_size)

                while True:
                    filename = person_dir / f"{name}_{counter}.jpg"
                    if not filename.exists():
                        break
                    counter += 1

                cv2.imwrite(str(filename), face_resize)
                print(f"ðŸ“¸ æ‰‹å‹•å„²å­˜ {filename.name}")
                counter += 1

cap.release()
cv2.destroyAllWindows()
